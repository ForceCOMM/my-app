# -*- coding: utf-8 -*-
"""Integration Of Vertex AI API, Sentiment Analysis Model, and Financial Records

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X7eZUbtK1o9SN0RNBWLPBYaF6ruTR4Ka
"""

import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Layer
from tensorflow.keras.preprocessing.text import tokenizer_from_json
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from scipy import stats
import firebase_admin
from firebase_admin import credentials, firestore, auth
import requests
import sys

if "google.colab" in sys.modules:
    from google.colab import auth

    auth.authenticate_user()

from google.cloud import aiplatform

from vertexai.generative_models import (
    GenerationConfig,
    GenerativeModel,
    HarmBlockThreshold,
    HarmCategory,
    Part,
)

from google.cloud import aiplatform

aiplatform.init(
    project="true-river-443407-h4",
    location="us-central1"
)

print("Vertex AI initialized successfully!")

class AttentionLayer(Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(
            name='attention_weight',
            shape=(input_shape[-1], 1),
            initializer='random_normal',
            trainable=True
        )
        super(AttentionLayer, self).build(input_shape)

    def call(self, x):
        e = tf.nn.tanh(tf.matmul(x, self.W))
        a = tf.nn.softmax(e, axis=1)
        output = x * a
        return tf.reduce_sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[-1])

model_ml = load_model("sentiment_model.h5", custom_objects={'AttentionLayer': AttentionLayer})

with open('tokenizer.json', 'r') as f:
    tokenizer_json = f.read()
tokenizer = tokenizer_from_json(tokenizer_json)

# Inisialisasi Firebase Admin SDK (gunakan file credentials yang sesuai)
cred = credentials.Certificate('true-river-443407-h4-8992fe4a3b7a.json')
firebase_admin.initialize_app(cred)

# Inisialisasi Firestore
db = firestore.client()

def ambil_uid_dari_api():
    """
    Mengambil UID dari API endpoint

    Returns:
    str: UID yang diterima dari API, atau None jika gagal
    """
    try:
        # URL API untuk mendapatkan UID
        api_url = "https://api-keuangan-116956501009.asia-southeast2.run.app/get-uid"

        # Mengambil UID
        response = requests.get(api_url)

        if response.status_code == 200:
            data = response.json()
            uid = data.get('uid')

            if uid:
                print(f"Berhasil mendapatkan UID dari API: {uid}")
                return uid
            else:
                print("Tidak ada UID yang ditemukan di respons API")
                return None
        else:
            print(f"Gagal mengambil UID. Status code: {response.status_code}")
            print(f"Pesan error: {response.text}")
            return None

    except requests.RequestException as e:
        print(f"Kesalahan dalam permintaan API: {e}")
        return None
    except Exception as e:
        print(f"Kesalahan tidak terduga: {e}")
        return None

def ambil_user_id_tertentu():
    """
    Mengambil semua user_id (uid) yang ada dalam koleksi 'keuangan'.
    Returns:
    List of user_ids.
    """
    keuangan_ref = db.collection('keuangan')
    documents = keuangan_ref.stream()

    user_ids = []
    for doc in documents:
        data = doc.to_dict()
        if 'uid' in data:
            user_ids.append(data['uid'])

    return user_ids

def ambil_data_keuangan_user(user_id):
    """
    Mengambil data transaksi dari Firestore dan mengembalikannya sebagai list of dictionaries.
    """
    # Mengakses koleksi keuangan
    keuangan_ref = db.collection('keuangan')
    query = keuangan_ref.where('uid', '==', user_id).get()

    if query:
        for doc in query:
            return doc.to_dict().get('keuangan', [])
    else:
        print(f"failed: {user_id}")
        return []

def tampilkan_data(data):
    """
    Menampilkan data yang telah diambil dari Firestore dalam format tabel.

    Parameters:
    data: List of dictionaries, data transaksi yang diambil dari Firestore.
    """
    # Mengubah list of dictionaries menjadi DataFrame
    df = pd.DataFrame(data)

    # Jika DataFrame kosong
    if df.empty:
        print("Tidak ada data yang ditemukan di Firestore.")
        return

    # Menampilkan DataFrame
    print("\nData Transaksi yang Diambil dari Firestore:")
    print(df.to_string(index=False))

def analisis_keuangan_umkm(data):
    """
    Menganalisis data keuangan UMKM harian

    Parameters:
    data: List of dictionaries with keys 'tanggal', 'pemasukan', 'pengeluaran'

    Returns:
    DataFrame dengan analisis, ringkasan statistik, dan prediksi
    """
    # Convert list of dictionaries to DataFrame
    df = pd.DataFrame(data)

    # Convert tanggal to datetime if it's not already
    df['tanggal'] = pd.to_datetime(df['tanggal'])

    # Calculate additional metrics
    df['keuntungan'] = df['pemasukan'] - df['pengeluaran']
    df['margin'] = (df['keuntungan'] / df['pemasukan'] * 100).round(2)

    # Calculate moving averages
    df['rata_pemasukan_7hari'] = df['pemasukan'].rolling(window=7, min_periods=1).mean()
    df['rata_pengeluaran_7hari'] = df['pengeluaran'].rolling(window=7, min_periods=1).mean()
    df['trend_keuntungan_7hari'] = df['keuntungan'].rolling(window=7, min_periods=1).mean()

    # Prediksi sederhana menggunakan analisis statistik
    def prediksi_bisnis(df):
        """
        Melakukan prediksi sederhana berdasarkan analisis statistik

        Returns:
        Dictionary berisi informasi prediksi
        """
        # Analisis regresi linear sederhana untuk keuntungan
        x = np.arange(len(df)).reshape(-1, 1)
        y = df['keuntungan'].values

        # Analisis regresi dan korelasi
        slope, _, r_value, p_value, _ = stats.linregress(x.flatten(), y)

        # Interpretasi prediksi
        if p_value < 0.05:
            if slope > 0:
                status = "Positif (Pertumbuhan)"
            else:
                status = "Negatif (Penurunan)"
        else:
            status = "Netral (Stabil)"

        # Informasi tambahan
        prediksi = {
            'status_prediksi': status,
            'slope_keuntungan': slope,
            'kekuatan_trend': abs(r_value),
        }

        return prediksi

    # Generate summary statistics
    ringkasan = {
        'total_pemasukan': df['pemasukan'].sum(),
        'total_pengeluaran': df['pengeluaran'].sum(),
        'total_keuntungan': df['keuntungan'].sum(),
        'rata_pemasukan': df['pemasukan'].mean(),
        'rata_pengeluaran': df['pengeluaran'].mean(),
        'rata_keuntungan': df['keuntungan'].mean(),
        'margin_rata_rata': df['margin'].mean(),
        'hari_profit_tertinggi': df.loc[df['keuntungan'].idxmax(), 'tanggal'],
        'profit_tertinggi': df['keuntungan'].max(),
        'hari_profit_terendah': df.loc[df['keuntungan'].idxmin(), 'tanggal'],
        'profit_terendah': df['keuntungan'].min()
    }

    # Tambahkan prediksi ke ringkasan
    prediksi = prediksi_bisnis(df)
    ringkasan.update(prediksi)

    def plot_trends():
        """Membuat visualisasi trend keuangan"""
        plt.figure(figsize=(12, 6))
        plt.plot(df['tanggal'], df['pemasukan'], label='Pemasukan')
        plt.plot(df['tanggal'], df['pengeluaran'], label='Pengeluaran')
        plt.plot(df['tanggal'], df['keuntungan'], label='Keuntungan')
        plt.title('Trend Keuangan UMKM')
        plt.xlabel('Tanggal')
        plt.ylabel('Jumlah (Rp)')
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

    return df, ringkasan, plot_trends

# Pertama, coba ambil UID dari API
api_uid = ambil_uid_dari_api()

if api_uid:
    # Jika berhasil mendapatkan UID dari API, gunakan UID tersebut
    user_id = api_uid
    print(f"Menggunakan UID dari API: {user_id}")
else:
    # Jika gagal, gunakan metode pengambilan user ID dari Firestore
    user_ids = ambil_user_id_tertentu()

    if user_ids:
        user_id = user_ids[0]
        print(f"Menggunakan user ID pertama dari Firestore: {user_id}")
    else:
        print("Tidak ada user ID yang ditemukan.")
        exit()

# Ambil data keuangan berdasarkan user_id
data_keuangan = ambil_data_keuangan_user(user_id)

if data_keuangan:
    # Analisis data keuangan
    df, ringkasan, plot_trends = analisis_keuangan_umkm(data_keuangan)

    # Cetak ringkasan analisis
    print("\nRingkasan Analisis:")
    for key, value in ringkasan.items():
        print(f"{key}: {value}")

    # Tampilkan tren keuangan
    plot_trends()
else:
    print("Tidak ada data keuangan untuk user ini.")

# # Mengambil data dari Firestore dan menjalankan analisis
# data_dari_firestore = ambil_data_dari_firestore()

# # Menampilkan data transaksi yang telah diambil
# tampilkan_data(data_dari_firestore)

# # Analisis data keuangan
# df, ringkasan, plot_trends = analisis_keuangan_umkm(data_dari_firestore)

# # Cetak ringkasan analisis
# print("\nRingkasan Analisis:")
# for key, value in ringkasan.items():
#     print(f"{key}: {value}")

# # Tampilkan tren keuangan
# plot_trends()

def preprocess_text(text, tokenizer, max_len=100):
    tokens = tokenizer.texts_to_sequences([text])
    padded_tokens = pad_sequences(tokens, maxlen=max_len, padding='post')
    return padded_tokens

def predict_sentiment(text, model, tokenizer):
    preprocessed_text = preprocess_text(text, tokenizer)
    prediction = model_ml.predict(preprocessed_text)
    sentiment = np.argmax(prediction, axis=1)
    return sentiment.item()

# Convert index to custom labels
def map_sentiment_to_label(sentiment_index):
    if sentiment_index == 2:
        return "positive"
    elif sentiment_index == 1:
        return "neutral"
    elif sentiment_index == 0:
        return "negative"
    else:
        return "Unknown"

def sentiment_summary(df, sentiment_model, text_column='text'):
    # Ensure the dataframe has the specified text column
    if text_column not in df.columns:
        raise ValueError(f"DataFrame must contain the column '{text_column}'")

    # Predict sentiment for each text in the specified column
    predictions = [predict_sentiment(text, sentiment_model, tokenizer) for text in df[text_column]]

    # Add predictions to the dataframe
    df['sentiment'] = predictions

    # Map sentiment to labels
    df['sentiment_label'] = df['sentiment'].map({
        0: 'Negative',
        1: 'Neutral',
        2: 'Positive'
    })

    # Count occurrences of each sentiment label
    sentiment_counts = df['sentiment_label'].value_counts()

    # Find the longest positive and negative texts
    longest_positive = df[df['sentiment'] == 2].loc[df[df['sentiment'] == 2][text_column].str.len().idxmax()]
    longest_negative = df[df['sentiment'] == 0].loc[df[df['sentiment'] == 0][text_column].str.len().idxmax()]

    return df, sentiment_counts, longest_positive, longest_negative

data = {
    'text': [
        "sukaaaa banget pake bodi serum tergiur beli",
        "kecewa sama produknya tidak sesuai",
        "barangnya jelek banget anjing kecewa penipu lu",
        "Barang sampai",
    ]
}

df = pd.DataFrame(data)

MODEL_ID = "gemini-1.5-pro-002"  # @param {type:"string"}

model = GenerativeModel(MODEL_ID)

df_summary, sentiment_counts, longest_positive, longest_negative = sentiment_summary(df, model_ml)

prompt = f"""
Analisis data keuangan UMKM dengan detail sebagai berikut:

Ringkasan Finansial:
- Total Pemasukan: {ringkasan['total_pemasukan']}
- Total Pengeluaran: {ringkasan['total_pengeluaran']}
- Total Keuntungan: {ringkasan['total_keuntungan']}
- Rata-rata Pemasukan: {ringkasan['rata_pemasukan']}
- Rata-rata Pengeluaran: {ringkasan['rata_pengeluaran']}
- Rata-rata Keuntungan: {ringkasan['rata_keuntungan']}
- Margin Rata-rata: {ringkasan['margin_rata_rata']}

Detail Profit:
- Tanggal Profit Tertinggi: {ringkasan['hari_profit_tertinggi']}
- Nilai Profit Tertinggi: {ringkasan['profit_tertinggi']}
- Tanggal Profit Terendah: {ringkasan['hari_profit_terendah']}
- Nilai Profit Terendah: {ringkasan['profit_terendah']}

Analisis Statistik:
- Status Prediksi: {ringkasan['status_prediksi']}
- Slope Keuntungan: {ringkasan['slope_keuntungan']}
- Kekuatan Trend: {ringkasan['kekuatan_trend']}

Analisis Sentimen:
- Total Komentar Positif: {sentiment_counts.get('Positive', 0)}
- Total Komentar Netral: {sentiment_counts.get('Neutral', 0)}
- Total Komentar Negatif: {sentiment_counts.get('Negative', 0)}
- Contoh Komentar Positif Terpanjang: {longest_positive['text']}
- Contoh Komentar Negatif Terpanjang: {longest_negative['text']}


"""

print(prompt)

#Load a example model with system instructions
example_model = GenerativeModel(
    MODEL_ID,
    system_instruction=[
        "Your mission is to create a connection of the prompt to make a SMES practical bussines decision in indonesian"
    ],
)

# Set model parameters
generation_config = GenerationConfig(
    temperature=0.9,
    top_p=1.0,
    top_k=32,
    candidate_count=1,
    max_output_tokens=150,
)

# Set safety settings
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
}

contents = [prompt]

print(example_model.count_tokens(contents))

# Prompt the model to generate content
response = example_model.generate_content(
    contents,
    generation_config=generation_config,
    safety_settings=safety_settings,
)

# Print the model response
print(f"\nAnswer:\n{response.text}")